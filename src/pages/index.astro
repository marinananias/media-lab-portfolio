---
import Layout from "../layouts/Layout.astro";
---

<Layout>
  <!-- COVER / LANDING -->
  <section id="cover" class="section">
    <div class="section-header">
      <div class="section-eyebrow">Cover / Landing</div>
    </div>

    <div class="cover-card">
      <h1 class="cover-name">Marina Ananias</h1>
      <p class="cover-line">
        BA in Computer Science and Music, Concentration in Neuroscience
      </p>
      <div class="identity">
        I build expressive, human-centered technologies that draw on behavioral,
        cognitive, and community data to expand creativity, deepen learning, and
        support human wellbeing and growth.
      </div>
      <div class="links-row">
        <span class="link-pill">Website</span>
        <span class="link-pill">Email</span>
        <!-- Replace with real links later, e.g.
        <a class="link-pill" href="https://marinaananias.com" target="_blank" rel="noreferrer">Website</a>
        -->
      </div>
    </div>
  </section>

  <!-- HOW TO READ THIS PORTFOLIO -->
  <section id="how-to-read" class="section">
    <div class="section-header">
      <div class="section-eyebrow">How to Read This Portfolio</div>
      <h2 class="section-title">Context & Navigation</h2>
    </div>

    <div class="htr-card">
      <p class="piece-body">
        This portfolio presents a curated selection of my interdisciplinary work.
        Each piece includes a concise description, relevant technical context,
        and an explanation of how it aligns with research directions explored at
        Opera of the Future, Responsive Environments, and Multisensory
        Intelligence. My aim is to give a clear view of how computation, sound,
        sensing, and human-centered design converge in my practice and research
        trajectory.
      </p>
    </div>
  </section>

  <!-- MOVEMENT I ‚Äî INTERFACES -->
  <section id="interfaces" class="section movement">
    <header class="movement-header">
      <div class="movement-title-row">
        <div>
          <div class="movement-label">Movement I ‚Äî Interfaces</div>
          <h2 class="movement-title">Where expression begins.</h2>
        </div>
      </div>
      <p class="movement-epigraph">
        ‚ÄúWhere expression begins in the hand, in motion, in the meeting of sound
        and touch.‚Äù
      </p>
      <p class="movement-intro">
        These works explore how accessible tools and interfaces can open
        musical expression to anyone‚Äîperformers, students, and people simply
        curious about sound.
      </p>
    </header>

    <div class="pieces">
      <!-- Piece 1 -->
      <article class="piece">
        <h3 class="piece-title">
          Piece 1 ‚Äî The MIDI Songwriter: A Harmonizing Hyperinstrument Prototype üé≠
        </h3>
        <p class="piece-media">
          Media: device photo, wiring diagrams, build video
        </p>

        <h4 class="piece-subheading">Description</h4>
        <p class="piece-body">
          The MIDI Songwriter is a hardware instrument designed to make harmony
          intuitive. Built during my internship at Nerd Musician, it translates
          tactile interaction into harmonically rich phrases, offering an
          accessible but expressive entry point into composition. I designed the
          enclosure, soldered components, programmed sensor mappings, and
          refined the musical logic to respond fluidly to user input.
        </p>

        <h4 class="piece-subheading">Technical Context</h4>
        <p class="piece-body">
          C++ on Arduino; analog sensors; DSP mapping strategies; MIDI-over-USB.
        </p>

        <h4 class="piece-subheading">Relevance</h4>
        <p class="piece-body">
          <strong>Opera of the Future:</strong> Embodies the ethos of
          hyperinstruments that understand user intention and expand expressive
          possibility.
        </p>
        <p class="piece-body">
          <strong>Responsive Environments:</strong> A small embedded sensing
          network transforming analog input into structured musical output.
        </p>
      </article>

      <!-- Piece 2 -->
      <article class="piece">
        <h3 class="piece-title">
          Piece 2 ‚Äî The Browser Keyboard: A Digital Interface for Accessible Music-Making üé≠üåå
        </h3>
        <p class="piece-media">
          Media: interaction video, UI image
        </p>

        <h4 class="piece-subheading">Description</h4>
        <p class="piece-body">
          This browser-based keyboard turns mouse movement into musical gesture,
          allowing users to compose and perform without physical instruments.
          Its minimalist design encourages intuitive exploration, making it
          ideal for beginners learning fundamental musical relationships.
        </p>

        <h4 class="piece-subheading">Technical Context</h4>
        <p class="piece-body">
          Scheme (Scamper), HTML5, JavaScript; cursor-to-sound mapping.
        </p>

        <h4 class="piece-subheading">Relevance</h4>
        <p class="piece-body">
          <strong>Opera of the Future:</strong> A digital hyperscore-like
          interface for democratizing composition.
        </p>
        <p class="piece-body">
          <strong>Multisensory Intelligence:</strong> Converts motor/visual
          input into structured sound‚Äîfoundational multimodal AI thinking.
        </p>
      </article>
    </div>

    <p class="movement-transition">
      If interfaces give form to expression, systems give it scale‚Äîshaping how
      communities learn, connect, and create meaning together.
    </p>
  </section>

  <!-- MOVEMENT II ‚Äî SYSTEMS -->
  <section id="systems" class="section movement">
    <header class="movement-header">
      <div class="movement-title-row">
        <div>
          <div class="movement-label">Movement II ‚Äî Systems</div>
          <h2 class="movement-title">
            Where technology becomes infrastructure.
          </h2>
        </div>
      </div>
      <p class="movement-epigraph">
        ‚ÄúWhere technology becomes infrastructure for belonging, opportunity, and
        collective imagination.‚Äù
      </p>
      <p class="movement-intro">
        These works show how creative computation can support large-scale
        communities, designing not just tools but ecosystems for participation
        and growth.
      </p>
    </header>

    <div class="pieces">
      <!-- Piece 3 -->
      <article class="piece">
        <h3 class="piece-title">
          Piece 3 ‚Äî BRASA: A Digital Ecosystem for a Global Community üé≠üåå
        </h3>
        <p class="piece-media">
          Media: system diagrams, screenshots, flows
        </p>

        <h4 class="piece-subheading">Description</h4>
        <p class="piece-body">
          As Director of Technology and later COO of BRASA‚Äîthe world‚Äôs largest
          network of Brazilian students abroad‚ÄîI led the redesign of the
          organization‚Äôs digital infrastructure. This included a new website,
          internal portal, mobile app, and unified database, transforming
          fragmented systems into a cohesive platform that supports conferences,
          mentorships, scholarships, and career opportunities for more than
          15,000 students. Our work increased site traffic by 170% and improved
          NPS by 105 points.
        </p>

        <h4 class="piece-subheading">Technical Context</h4>
        <p class="piece-body">
          React/Next.js, Django REST, PostgreSQL, AWS, Docker, CI/CD; leadership
          of a 15+ person cross-functional team.
        </p>

        <h4 class="piece-subheading">Relevance</h4>
        <p class="piece-body">
          <strong>Opera of the Future:</strong> A community-scale expressive
          system‚Äîa ‚ÄúCity Symphony‚Äù of participation and learning.
        </p>
        <p class="piece-body">
          <strong>Responsive Environments:</strong> A large distributed sensor
          network capturing behavioral and social signals.
        </p>
        <p class="piece-body">
          <strong>Multisensory Intelligence:</strong> A real-world setting for
          multimodal AI supporting wellbeing and creativity.
        </p>
      </article>

      <!-- Piece 4 -->
      <article class="piece">
        <h3 class="piece-title">
          Piece 4 ‚Äî The Community Calendar: Rapid Co-Design for Real Needs üï∏Ô∏èüåå
        </h3>
        <p class="piece-media">
          Media: screen recordings
        </p>

        <h4 class="piece-subheading">Description</h4>
        <p class="piece-body">
          Built during a company hackathon, this React Native app supports
          coordination and engagement for a community partner. I collaborated
          across design and engineering to quickly gather requirements,
          prototype interactions, and deliver an intuitive scheduling tool.
        </p>

        <h4 class="piece-subheading">Technical Context</h4>
        <p class="piece-body">
          React Native; state management; mobile UX.
        </p>

        <h4 class="piece-subheading">Relevance</h4>
        <p class="piece-body">
          <strong>Responsive Environments:</strong> A mediation layer between
          people and their environments.
        </p>
        <p class="piece-body">
          <strong>Multisensory Intelligence:</strong> A practical system
          supporting productivity and wellbeing.
        </p>
      </article>
    </div>

    <p class="movement-transition">
      If systems let communities speak, signals let individuals be
      heard‚Äîrevealing patterns of mind, behavior, and semantics.
    </p>
  </section>

  <!-- MOVEMENT III ‚Äî SIGNALS -->
  <section id="signals" class="section movement">
    <header class="movement-header">
      <div class="movement-title-row">
        <div>
          <div class="movement-label">Movement III ‚Äî Signals</div>
          <h2 class="movement-title">
            Where hidden patterns become audible and intelligible.
          </h2>
        </div>
      </div>
      <p class="movement-epigraph">
        ‚ÄúWhere hidden patterns‚Äîneural, behavioral, or linguistic‚Äîtake on musical
        and intelligible form.‚Äù
      </p>
      <p class="movement-intro">
        These works explore how internal states and semantic cues can be
        interpreted computationally and transformed into creative or functional
        feedback.
      </p>
    </header>

    <div class="pieces">
      <!-- Piece 5 -->
      <article class="piece">
        <h3 class="piece-title">
          Piece 5 ‚Äî Brainwaves to Sound: Making Cognitive Patterns Audible üé≠üåå
        </h3>
        <p class="piece-media">
          Media: EEG-to-audio diagrams, demo video
        </p>

        <h4 class="piece-subheading">Description</h4>
        <p class="piece-body">
          This project sonifies patterns of neural activity, exploring how
          internal cognitive states can be made perceptible and creatively
          meaningful. I designed the processing pipeline and mapping strategies,
          translating brain features into evolving musical textures that reflect
          emotional and cognitive shifts.
        </p>

        <h4 class="piece-subheading">Technical Context</h4>
        <p class="piece-body">
          Python; EEG preprocessing; band-power features; timbre/harmony
          mapping.
        </p>

        <h4 class="piece-subheading">Relevance</h4>
        <p class="piece-body">
          <strong>Opera of the Future:</strong> A cognitive hyperinstrument
          exploring sound for learning and wellbeing.
        </p>
        <p class="piece-body">
          <strong>Responsive Environments:</strong> Physiological sensing
          integrated with expressive feedback.
        </p>
        <p class="piece-body">
          <strong>Multisensory Intelligence:</strong> Cross-modal translation of
          neural states into structured sonic output.
        </p>
      </article>

      <!-- Piece 6 -->
      <article class="piece">
        <h3 class="piece-title">
          Piece 6 ‚Äî Semantic Mapping Engine: AI That Understands Human Intent üååüï∏Ô∏è
        </h3>
        <p class="piece-media">
          Media: architecture diagram
        </p>

        <h4 class="piece-subheading">Description</h4>
        <p class="piece-body">
          I designed an AI-driven semantic engine that improves intent
          recognition in a customer-support chatbot by using OpenAI embeddings
          to classify user messages with higher accuracy and interpretability.
          This significantly reduced manual intervention and improved system
          stability across thousands of interactions.
        </p>

        <h4 class="piece-subheading">Technical Context</h4>
        <p class="piece-body">
          Python/Node; embedding-based semantic similarity; production-grade
          API.
        </p>

        <h4 class="piece-subheading">Relevance</h4>
        <p class="piece-body">
          <strong>Multisensory Intelligence:</strong> Human‚ÄìAI symbiosis and
          robust multimodal interpretation.
        </p>
        <p class="piece-body">
          <strong>Responsive Environments:</strong> Treats linguistic data as a
          noisy sensor signal requiring inference.
        </p>
      </article>
    </div>

    <p class="movement-transition">
      Signals shape meaning, but music gives that meaning form‚Äîa language that
      reveals how you think, imagine, and create.
    </p>
  </section>

  <!-- MOVEMENT IV ‚Äî LANGUAGE -->
  <section id="language" class="section movement">
    <header class="movement-header">
      <div class="movement-title-row">
        <div>
          <div class="movement-label">Movement IV ‚Äî Language</div>
          <h2 class="movement-title">
            Where ideas become sound and structure.
          </h2>
        </div>
      </div>
      <p class="movement-epigraph">
        ‚ÄúWhere ideas become sound, structure becomes narrative, and the universe
        resonates in musical form.‚Äù
      </p>
      <p class="movement-intro">
        This movement highlights my compositional work, where scientific
        metaphor and musical intuition intersect.
      </p>
    </header>

    <div class="pieces">
      <!-- Piece 7 -->
      <article class="piece">
        <h3 class="piece-title">
          Piece 7 ‚Äî The Universe as a Musical: An Instrumental Composition üé≠
        </h3>
        <p class="piece-media">
          Media: audio recording, score excerpt, program notes
        </p>

        <h4 class="piece-subheading">Description</h4>
        <p class="piece-body">
          This piece imagines the universe as a vast musical narrative,
          translating concepts like expansion, resonance, and gravitational
          tension into motif, harmony, and timbre. Its form mirrors
          cosmological cycles‚Äîdensities collapsing into clarity; tension
          dissolving into stillness‚Äîreflecting my belief that music can
          illuminate structures beyond the reach of language.
        </p>

        <h4 class="piece-subheading">Technical Context</h4>
        <p class="piece-body">
          Composed using notation and digital audio software; explores extended
          harmony and dynamic timbral motion.
        </p>

        <h4 class="piece-subheading">Relevance</h4>
        <p class="piece-body">
          <strong>Opera of the Future:</strong> Demonstrates narrative thinking,
          expressive structure, and cross-disciplinary imagination‚Äîcore to
          developing new musical and operatic technologies.
        </p>

        <h4 class="piece-subheading">Additional Works</h4>
        <p class="piece-body">
          A short playlist of selected pieces with brief conceptual notes.
        </p>
      </article>
    </div>
  </section>

  <!-- FUTURE DIRECTIONS & RESEARCH ALIGNMENT -->
  <section id="future" class="section">
    <div class="section-header">
      <div class="section-eyebrow">Future Directions &amp; Research Alignment</div>
      <h2 class="section-title">Where This Work is Heading</h2>
    </div>

    <div class="future-section">
      <p class="piece-body">
        Drawing on experience across musical interfaces, sensing systems, AI
        interaction, and community-scale platforms, I aim to develop expressive
        technologies that support creativity, learning, and wellbeing. My
        long-term research vision centers on building systems that listen to
        people‚Äînot only through gesture or language, but through behavior,
        cognition, and participation‚Äîand respond in ways that help individuals
        and communities grow.
      </p>

      <ul class="future-list">
        <li class="future-item">
          <div class="future-title">Emotional Hyperinstrument</div>
          <p class="future-body">
            I hope to explore instruments that engage with cognitive and
            emotional cues, adapting musical output to support self-regulation,
            learning, and expressive depth.
          </p>
        </li>
        <li class="future-item">
          <div class="future-title">AI Co-Composer for Learning</div>
          <p class="future-body">
            I envision intelligent tools that scaffold musical creativity,
            offering adaptive suggestions in harmony, structure, and variation
            while preserving human authorship.
          </p>
        </li>
        <li class="future-item">
          <div class="future-title">
            Sonic Systems for Collective Participation
          </div>
          <p class="future-body">
            I want to design community-scale musical experiences where
            collective behavior‚Äîdata flows, movement, communication‚Äîbecomes a
            shared sonic narrative.
          </p>
        </li>
      </ul>
    </div>
  </section>
</Layout>
