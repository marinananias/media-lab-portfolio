---
import Layout from "../layouts/Layout.astro";
---

<Layout>
  <!-- COVER / LANDING -->
  <section id="landing" class="section">

    <div class="cover-card">
      <h1 class="cover-name">Marina Ananias</h1>
      <p class="cover-line">
        BA in Computer Science and Music, Concentration in Neuroscience
      </p>
      <div class="identity">
        I design expressive, multisensory musical systems that investigate how 
        people form creative agency when interaction is uncertain, exploratory, 
        or still forming. My work combines instrument design, sensing systems, AI interaction, and 
        large-scale platforms to study <b>how interfaces can listen to tentative human
        input</b> and respond to human needs in ways that <b>expand creativity and support
        learning, wellbeing, and growth.</b>
      </div>
      <div class="links-row">
        <a class="link-pill" href="mailto:ananias.marina@gmail.com">Email</a>
        <a class="link-pill" href="https://marinaananias.com" target="_blank" rel="noreferrer">Website</a>
      </div>
    </div>
  </section>

  <!-- HOW TO READ THIS PORTFOLIO -->
  <section id="how-to-read" class="section">
    <div class="section-header">
      <!-- <div class="section-eyebrow">How to Read This Portfolio</div> -->
      <!-- <h2 class="section-title">Context &amp; Navigation</h2> -->
    </div>

    <!-- <div class="htr-card">
      <p class="piece-body">
        This portfolio presents a curated selection of my interdisciplinary work.
        Each piece includes a concise description, relevant technical context,
        and an explanation of how it aligns with research directions explored at
        <b>Opera of the Future, Responsive Environments, and Multisensory
        Intelligence</b>. My aim is to give a clear view of how computation, sound,
        sensing, and human-centered design converge in my practice and research
        trajectory
      </p>
    </div> -->
  </section>

  <!-- MOVEMENT I — INTERFACES -->
  <section id="interfaces" class="section movement movement--interfaces">
    <header class="movement-header">
      <div class="movement-title-row">
        <div>
          <div class="movement-label">Movement I — Interfaces</div>
          <h2 class="movement-title">Where expression begins</h2>
        </div>
      </div>
      <!-- <p class="movement-intro">
        How can tactile, non-symbolic interaction support intuitive understanding of harmony for novice musicians?
        Can minimal visual-motor interaction support early-stage musical exploration without physical instruments?
      </p> -->
    </header>

    <div class="pieces">
      <!-- Piece 1: MIDI Songwriter -->
      <article class="piece">
        <h3 class="piece-title">
          Piece 1 — MIDI Songwriter
        </h3>

        <div class="piece-media-label">How can tactile, non-symbolic interaction support intuitive understanding of harmony for novice musicians?</div>

        <p class="piece-overview">
         <b>Concept:</b> The MIDI Songwriter is a hardware instrument designed to make harmony intuitive. 
          Rather than requiring theoretical knowledge, the instrument encodes harmonic 
          relationships into its physical affordances, allowing non-expert musicians to create coherent musical phrases
          even when their gestures are still exploratory or imprecise. This project explores how physical affordances can
          preserve agency when users do not yet have explicit harmonic intent.<br/><br/>  
          <b>Method & Implementation:</b> Designed and fabricated custom enclosure and tactile interface; 
          developed embedded firmware for real-time sensor processing and MIDI communication with visual feedback 
          through RGB LEDs to guide user interaction.
         </p> 

        <div class="piece-meta-row">
          <span class="piece-meta-pill">C++</span>
          <span class="piece-meta-pill">Arduino</span>
          <span class="piece-meta-pill">Analog Sensors</span>
          <span class="piece-meta-pill">MIDI-over-USB</span>
          <span class="piece-meta-pill">Hardware &amp; Firmware Design</span>
        </div>

        <div class="piece-media-block">
          <div class="piece-media-grid piece-media-grid--three">
            <figure class="media-figure">
              <div class="media-frame media-frame--hero">
                <img
                  src="/media/midi-songwriter-device.jpeg"
                  alt="MIDI Songwriter assembled device glowing blue on a desk"
                  class="media-img"
                />
              </div>
              <figcaption class="media-caption">
                Final assembled hardware prototype
              </figcaption>
            </figure>

            <figure class="media-figure">
              <div class="media-frame media-frame--standard">
                <img
                  src="/media/midi-songwriter-enclosure.png"
                  alt="Laser-cut enclosure layout for the MIDI Songwriter"
                  class="media-img"
                />
              </div>
              <figcaption class="media-caption">
                Laser-cut enclosure design
              </figcaption>
            </figure>

            <figure class="media-figure">
              <div class="media-frame media-frame--standard">
                <img
                  src="/media/midi-songwriter-wiring.png"
                  alt="Internal wiring diagram of the MIDI Songwriter created in Fritzing"
                  class="media-img"
                />
              </div>
              <figcaption class="media-caption">
                Wiring diagram connecting sensors, LEDs, and the
                microcontroller
              </figcaption>
            </figure>

          </div>
        </div>

        <div class="piece-meta-label">Relevance</div>
        <ul class="piece-meta-list">
          <li>
            <strong>Opera of the Future:</strong> Hyperinstrument-inspired beginner-centered expressivity.
          </li>
          <li>
            <strong>Responsive Environments:</strong> Physical sensing as a primary musical interface.
          </li>
        </ul>

      </article>

      <!-- Piece 2: Browser Keyboard -->
      <article class="piece">
        <h3 class="piece-title">
          Piece 2 — Browser-Based Keyboard
        </h3>

        <div class="piece-media-label">Can minimal visual-motor interaction support early-stage musical exploration when users lack confidence, precision, or prior knowledge?</div>

        <div class="piece-split piece-split--image-left">
          <!-- LEFT: image + caption -->
          <div class="piece-split-media">
            <figure class="media-figure">
              <div class="media-frame media-frame--medium">
                <img
                  src="/media/midi-keyboard-151.png"
                  alt="Browser-based keyboard interface mapping cursor movement to pitch and timbre"
                  class="media-img"
                />
              </div>
              <figcaption class="media-caption">
                Browser-based interface used in classroom settings to teach basic harmony and melodic patterns
              </figcaption>
            </figure>
          </div>

          <!-- RIGHT: text + tags + relevance -->
          <div class="piece-split-text">
            <p class="piece-overview--onegrid">
              <b>Concept:</b> This browser-based keyboard maps cursor movement to pitch and harmonic structure, 
              enabling users to explore melody and harmony using only a mouse or trackpad.<br/><br/>
              <b>Method & Implementation:</b> Implemented cursor-to-sound mappings in Scheme; 
              Designed interface constraints to reduce cognitive overload for beginners.
            </p>

            <div class="piece-meta-row" style="margin-top: 0.9rem;">
              <span class="piece-meta-pill">Scheme (Scamper)</span>
              <span class="piece-meta-pill">HTML5</span>
              <span class="piece-meta-pill">JavaScript</span>
              <span class="piece-meta-pill">Sound mapping</span>
            </div>

          </div>
          <div class="piece-relevance">
            <div class="piece-meta-label">Relevance</div>
            <ul class="piece-meta-list">
              <li>
                <strong>Opera of the Future:</strong>
                Hyperscore-inspired democratization of composition.
              </li>
              <li>
                <strong>Multisensory Intelligence:</strong>
                Early example of multimodal translation (visual → auditory) for creative expression.
              </li>
            </ul>
          </div>
        </div>
      </article>
    </div>

    <p class="movement-transition">
      If interfaces give form to expression, systems give it scale. Shaping how
      communities learn, connect, and create meaning together.
    </p>
  </section>

  <!-- MOVEMENT II — SYSTEMS -->
  <section id="systems" class="section movement movement--systems">
    <header class="movement-header">
      <div class="movement-title-row">
        <div>
          <div class="movement-label">Movement II — Systems</div>
          <h2 class="movement-title">
            Where technology becomes infrastructure
          </h2>
        </div>
      </div>
      <!-- <p class="movement-intro">
        <i>Where technology becomes infrastructure for belonging, opportunity, and
        collective imagination.</i> These works show how creative computation can support large-scale
        communities, designing not just tools but ecosystems for participation
        and growth.
      </p> -->
    </header>

    <!-- Piece 3: BRASA ecosystem -->
    <article class="piece">
      <h3 class="piece-title">
        Piece 3 — BRASA Digital Ecosystem
      </h3>

      <div class="piece-media-label">How can digital platforms support belonging, opportunity, and collective imagination in large, distributed communities?</div>

      <p class="piece-body">
        <b>Concept:</b> As Director of Technology and later COO, I led the redesign of BRASA's digital ecosystem, 
          transforming fragmented tools into a unified system supporting conferences, mentorship, 
          scholarships, and community engagement for over 15,000 students. Beyond scale, this work examined how
          digital systems can support participation when users are navigating uncertainty, new institutions, 
          unfamiliar norms, and unequal access to information. The same design question recurs here: 
          how systems can invite agency without assuming confidence or prior expertise. <br/><br/>
        <b>Method & Implementation:</b> Designed and deployed full-stack <a class="a-brasa" href="https://gobrasa.org" target="_blank">website</a>, <a class="a-brasa" href="https://portalbrasa.gobrasa.org/" target="_blank">portal</a>, <a class="a-brasa" href="https://play.google.com/store/apps/details?id=com.brasa.brasapp&hl=en_US" target="_blank">app</a>, and database systems; 
        Led cross-functional Agile teams and defined scalable technical processes; Measured engagement through traffic analytics and NPS.
      </p>

      <div class="piece-meta-row" style="margin-top: 0.9rem;">
        <span class="piece-meta-pill">ReactJS & React Native</span>
        <span class="piece-meta-pill">Next.js</span>
        <span class="piece-meta-pill">Django REST Framework</span>
        <span class="piece-meta-pill">Python</span>
        <span class="piece-meta-pill">Typescript</span>
        <span class="piece-meta-pill">Docker</span>
        <span class="piece-meta-pill">AWS</span>
        <span class="piece-meta-pill">PostgreSQL</span>
        <span class="piece-meta-pill">Product Management</span>
        <span class="piece-meta-pill">Software Development Life Cycle</span>
        <span class="piece-meta-pill">Leadership of Cross-Functional Team</span>
      </div>
  
      <div class="piece-media-block">
        <div class="piece-media-grid piece-media-grid--three--brasa">

          <figure class="media-figure">
            <div class="media-frame media-frame--medium">
              <img
                src="/media/brasa-app.png"
                alt="Mockups of the official BRASA mobile app on multiple phones"
                class="media-img"
              />
            </div>
            <figcaption class="media-caption">
              BRASA mobile app QR codes and mockups
            </figcaption>
          </figure>

          <figure class="media-figure">
            <div class="media-frame media-frame--medium">
              <img
                src="/media/brasa-portal-gobrasa.png"
                alt=""
                class="media-img"
              />
            </div>
            <figcaption class="media-caption">
              BRASA website and portal screenshots
            </figcaption>
          </figure>

          <figure class="media-figure">
            <div class="media-frame media-frame--medium" data-dark-overlay="true">
              <img
                src="/media/brasa-uml-diagram.png"
                alt="Relational database schema for the BRASA platform"
                class="media-img"
              />
            </div>
            <figcaption class="media-caption">
              UML database schema connecting everything in a single ecosystem
            </figcaption>
          </figure>
        </div>

        <div class="piece-relevance">
          <div class="piece-meta-label">Relevance</div>
          <ul class="piece-meta-list">
            <li>
              <strong>Opera of the Future:</strong>
              Distributed sensing of community behavior.
            </li>
            <li>
              <strong>Multisensory Intelligence:</strong>
              Real-world multimodal data at social scale.
            </li>
          </ul>
        </div>
      </article>

    <p class="movement-transition">
      If systems let communities speak, signals let individuals be
      heard. Revealing patterns of mind, behavior, and semantics.
    </p>
  </section>

  <!-- MOVEMENT III — SIGNALS -->
  <section id="signals" class="section movement movement--signals">
    <header class="movement-header">
      <div class="movement-title-row">
        <div>
          <div class="movement-label">Movement III — Signals</div>
          <h2 class="movement-title">
            Where hidden patterns become audible and intelligible
          </h2>
        </div>
      </div>
      <!-- <p class="movement-intro">
        <i>Where hidden patterns, neural, behavioral, or linguistic, take on musical
        and intelligible form.</i>These works explore how internal states and semantic cues can be
        interpreted computationally and transformed into creative or functional
        feedback
      </p> -->
    </header>

      <!-- Piece 4: Brainwaves to Sound -->
      <article class="piece">
        <h3 class="piece-title">
          Piece 4 — Brainwaves to Sound
        </h3>

        <div class="piece-media-label">How do people interpret and attribute meaning to sound generated from ambiguous biosignals when no explicit semantic mapping is provided?</div>

        <div class="piece-split piece-split--image-left">
          <!-- LEFT: image + caption -->
          <div class="piece-split-media">
            <figure class="media-figure">
              <div class="media-frame media-frame--medium">
                 <video
                  class="media-video"
                  controls
                  src="/media/brainwave-to-music-video.mp4"
                >
                  Your browser does not support the video tag
              </div>
              <figcaption class="media-caption">
                Exploratory demo of EEG features mapped to study how listeners attribute meaning under ambiguous input
              </figcaption>
            </figure>
            <div class="piece-relevance">
              <div class="piece-meta-label"><br>Relevance</div>
              <ul class="piece-meta-list">
                <li>
                  <strong>Opera of the Future:</strong>
                  Cognitive hyperinstrument exploring expressive sound, learning, and agency.
                </li>
                <li>
                  <strong>Responsive Environments:</strong>
                  Physiological sensing with expressive feedback.
                </li>
                <li>
                  <strong>Multisensory Intelligence:</strong>
                  Cross-modal representation of internal states.
                </li>
              </ul>
            </div>
          </div>

          <!-- RIGHT: text + tags + relevance -->
          <div class="piece-split-text">
            <p class="piece-overview--onegrid">
              <b>Concept:</b> Sonification system designed as an exploratory probe, 
              mapping EEG signal features to generative sound without disclosing
              the mapping logic. Rather than prioritizing physiological accuracy,
              the prototype was designed to probe how listeners listen for coherence,
              agency, and meaning when sound is driven by an invisible, non-volitional
              signal.<br/><br/>
              <b>Research Probe:</b> Demonstrated in a classroom setting using prerecorded EEG data, allowing multiple listeners to simultaneously observe, interpret, and discuss the output in real time<br/><br/>
              <b>Insight & Next Iteration:</b> During discussion, listener questions focused
              on how the sound might be used compositionally, rather than on how one might 
              influence or control it. This framing suggested that, in the absence of an
              interpretable feedback loop or locus of agency, listeners understood the output
              primarily as an aesthetic artifact rather than an expressive, meaning-bearing interface.
              As a next iteration, I aim to introduce live EEG input and a constrained feedback loop,
              allowing participants to explore intentional influence over sound and directly compare
              passive versus interactive meaning-making.
            </p>

            <div class="piece-meta-row" style="margin-top: 0.9rem;">
              <span class="piece-meta-pill">Python</span>
              <span class="piece-meta-pill">EEG Processing</span>
              <span class="piece-meta-pill">Timbre/Harmony Mapping</span>
            </div>
          </div>

        </div>
      </article>

    <p class="movement-transition">
      Signals shape meaning, but music gives that meaning form. A language that
      reveals how we think, imagine, and create
    </p>
  </section>

  <!-- MOVEMENT IV — LANGUAGE -->
  <section id="language" class="section movement movement--language">
    <header class="movement-header">
      <div class="movement-title-row">
        <div>
          <div class="movement-label">Movement IV — Language</div>
          <h2 class="movement-title">
            Where ideas become sound and structure
          </h2>
        </div>
      </div>
      <!-- <p class="movement-intro">
        <i>Where ideas become sound, structure becomes narrative, and the universe
        resonates in musical form.</i> This movement highlights my compositional work, where scientificmetaphor and musical intuition intersect
        metaphor and musical intuition intersect
      </p> -->
    </header>

    <!-- Piece 5: Composition -->
    <article class="piece">
      <h3 class="piece-title">Piece 5 — The Universe as a Musical</h3>
      <div class="piece-media-label">How can musical form communicate complex, non-linguistic structures such as cosmological processes?</div>

      <div class="piece-split piece-split--image-left">
        <!-- LEFT COLUMN: DAW + Audio + Caption -->
        <div class="piece-split-media">
          <figure class="media-figure">
            <div class="media-frame media-frame--hero">
              <img
                src="/media/gravitational-waves-garageband.png"
                alt="DAW session view with layered textures and automation lanes"
                class="media-img"
              />
            </div>

            <!-- Audio BELOW the image -->
            <audio
              class="media-audio"
              controls
              src="/media/gravitational-waves-audio.mp3"
              style="margin-top: 0.9rem; width: 100%; border-radius: 12px;"
            >
              Your browser does not support the audio element.
            </audio>
            <figcaption class="media-caption">
              DAW session view and audio excerpt of "The Universe as a Musical"
            </figcaption>
          </figure>
          <div class="piece-meta-label">Relevance</div>
          <ul class="piece-meta-list">
            <li>
              <strong>Opera of the Future:</strong> Explores musical narrative, expressive 
              structure, and imaginative cross-disciplinary thinking foundational for 
              new operatic and interactive musical systems.
            </li>
          </ul>
        </div>

        <!-- RIGHT COLUMN: Description + Meta + Relevance -->
        <div class="piece-split-text">

          <!-- Overview paragraph -->
          <p class="piece-overview--onegrid">
            <b>Concept:</b> This composition interprets the cosmological phenomena of black hole collision and creation of gravitational waves through musical form. This piece reflects my broader interest in how non-linguistic structures can be made perceptible and interpretable, a concern that later informs my work on interactive and adaptive musical systems.<br/><br/>
            <b>Method & Implementation:</b> Composed using a Digital Audio Workstation (DAW); Employed techniques such as spectral morphing, microtonality, and evolving textures to reflect scientific concepts musically
          </p>

          <!-- Meta Chips -->
          <div class="piece-meta-row">
            <span class="piece-meta-pill">Digital Audio Workstation</span>
            <span class="piece-meta-pill">Extended Harmony</span>
            <span class="piece-meta-pill">Dynamic Timbre Design</span>
            <span class="piece-meta-pill">Narrative Composition</span>
          </div>

          <p class="supplementaty"><i>Supplementary note (optional):</i> Written companion describing scientific inspiration and compositional structure of this piece is <a style="text-decoration: underline;" href="https://drive.google.com/file/d/1OWrPnzRV62v8rlJBdf4DvzIg-CBlXjrV/view?usp=sharing" target="_blank">available</a>.</p>
        </div>
      <!-- FULL-WIDTH RELEVANCE -->
        <!-- <div class="piece-relevance">
          <div class="piece-meta-label">Relevance</div>
          <ul class="piece-meta-list">
            <li>
              <strong>Opera of the Future:</strong> Explores musical narrative, expressive 
              structure, and imaginative cross-disciplinary thinking foundational for 
              new operatic and interactive musical systems.
            </li>
          </ul>
        </div> -->
    </article>
  </section>

  <!-- FUTURE DIRECTIONS & RESEARCH ALIGNMENT -->
  <section id="future" class="section">
    <div class="section-header">
      <div class="section-eyebrow">Future Directions</div>
      <h2 class="section-title">Where This Work is Heading</h2>
    </div>

    <div class="future-section">
      <p class="piece-body">
        Building on these projects, my future research will focus on developing adaptive musical systems
        that respond to cognitive, emotional, and behavioral signals while preserving human agency under
        uncertainty. I am particularly interested in instruments that learn from users over time, 
        co-evolving expressive possibilities rather than prescribing them, and in deploying these systems
        within real educational and community contexts.
      </p>

      <!-- <ul class="future-list">
        <li class="future-item">
          <div class="future-title">Emotional Hyperinstrument</div>
          <p class="future-body">
            I hope to explore instruments that engage with cognitive and
            emotional cues, adapting musical output to support self-regulation,
            learning, and expressive depth
          </p>
        </li>
        <li class="future-item">
          <div class="future-title">AI Co-Composer for Learning</div>
          <p class="future-body">
            I envision intelligent tools that scaffold musical creativity,
            offering adaptive suggestions in harmony, structure, and variation
            while preserving human authorship
          </p>
        </li>
        <li class="future-item">
          <div class="future-title">
            Sonic Systems for Collective Participation
          </div>
          <p class="future-body">
            I want to design community-scale musical experiences where
            collective behavior—data flows, movement, communication—becomes a
            shared sonic narrative
          </p>
        </li>
      </ul> -->
    </div>
  </section>
</Layout>
